{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "# prepare requests & load as JSON\n",
    "\n",
    "gis = requests.get(\"https://services.arcgis.com/sFnw0xNflSi8J0uh/ArcGIS/rest/services?f=pjson\") # select datasets from this - just a few\n",
    "plans = requests.get(\"https://gis.bostonplans.org/hosting/rest/services?f=pjson\") # most datasets\n",
    "portal = requests.get(\"https://gisportal.boston.gov/arcgis/rest/services?f=pjson\") # second most datasets\n",
    "\n",
    "gis_data = gis.json()\n",
    "plans_data = plans.json()\n",
    "portal_data = portal.json()\n",
    "\n",
    "# because one server is organized differently,\n",
    "# make a list so we can parse it later\n",
    "\n",
    "# folders = []\n",
    "# for f in portal_data['folders']:\n",
    "#     folders.append(f)\n",
    "\n",
    "# make a data dictionary so we can parse efficiently\n",
    "\n",
    "data = {\n",
    "  \"servers\": [\n",
    "      {\n",
    "        \"url\": \"https://services.arcgis.com/sFnw0xNflSi8J0uh/ArcGIS/rest/services\",\n",
    "        \"data\": gis_data,\n",
    "        \"name\": \"bostongis\",\n",
    "      },\n",
    "      {\n",
    "        \"url\": \"https://gis.bostonplans.org/hosting/rest/services\",\n",
    "        \"data\": plans_data,\n",
    "        \"name\": \"bostonplans\",\n",
    "      },\n",
    "      {\n",
    "        \"url\": \"https://gisportal.boston.gov/arcgis/rest/services\",\n",
    "        \"data\": portal_data,\n",
    "        \"name\": \"gisportal\",\n",
    "      }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the giant queries we'll be using over and over\n",
    "\n",
    "query1=\"query?where=1%3D1&objectIds=&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&resultType=none&distance=0.0&units=esriSRUnit_Meter&relationParam=&returnGeodetic=false&outFields=*&returnGeometry=true&returnCentroid=false&returnEnvelope=false&featureEncoding=esriDefault&multipatchOption=xyFootprint&maxAllowableOffset=&geometryPrecision=&outSR=4326&defaultSR=&datumTransformation=&applyVCSProjection=false&returnIdsOnly=false&returnUniqueIdsOnly=false&returnCountOnly=false&returnExtentOnly=false&returnQueryGeometry=false&returnDistinctValues=false&cacheHint=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&having=&resultOffset=&resultRecordCount=&returnZ=false&returnM=false&returnTrueCurves=false&returnExceededLimitFeatures=true&quantizationParameters=&sqlFormat=none&f=pjson&token=\"\n",
    "query2=\"/query?where=1%3D1&objectIds=&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&distance=&units=esriSRUnit_Foot&relationParam=&outFields=*&returnGeometry=true&maxAllowableOffset=&geometryPrecision=&outSR=4326&havingClause=&gdbVersion=&historicMoment=&returnDistinctValues=false&returnIdsOnly=false&returnCountOnly=false&returnExtentOnly=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&returnZ=false&returnM=false&multipatchOption=xyFootprint&resultOffset=&resultRecordCount=&returnTrueCurves=false&returnExceededLimitFeatures=false&quantizationParameters=&returnCentroid=false&timeReferenceUnknownClient=false&sqlFormat=none&resultType=&featureEncoding=esriDefault&datumTransformation=&f=pjson\"\n",
    "\n",
    "# open the target JSON file to filter for only those datasets listed in target\n",
    "\n",
    "with open('../inputs/target.json') as f:\n",
    "    target=json.load(f)\n",
    "\n",
    "# open the snapshot json file where we'll write our data\n",
    "\n",
    "with open('../inputs/snapshot.json') as f:\n",
    "    snapshot=json.load(f)\n",
    "\n",
    "snapshot['servers']=[ ]\n",
    "serverCount=0\n",
    "\n",
    "# this is the big looping loop\n",
    "\n",
    "for server in data['servers']:   # SERVER LOOP\n",
    "\n",
    "    serviceCount=0\n",
    "    new={ \"url\": server['url'], \"name\": server['name'], \"services\": [ { \"featureServers\": [], \"mapServers\": [] } ], \"folders\": [ ] }\n",
    "    snapshot['servers'].append(new)\n",
    "\n",
    "    layerCount=0\n",
    "\n",
    "    for service in server['data']['services']:    # SITE ROOT SERVICES LOOP\n",
    "\n",
    "        if service['name'] in target and service['type'] == 'FeatureServer':\n",
    "            url=f\"{server['url']}/{service['name']}/{service['type']}\"\n",
    "            url_req=requests.get(f\"{url}?f=pjson\")\n",
    "            url_json=url_req.json()\n",
    "            new={ \"url\": url, \"name\": service['name'], \"layers\": [] }\n",
    "            snapshot['servers'][serverCount]['services'][serviceCount]['featureServers'].append(new)\n",
    "\n",
    "            for layer in url_json['layers']:    # SITE ROOT SERVICE LAYERS LOOP\n",
    "\n",
    "                layerUrl=f\"{url}/{layer['id']}/{query1}\"\n",
    "                new={ \"name\": layer['name'], \"layerUrl\": layerUrl}\n",
    "                snapshot['servers'][serverCount]['services'][serviceCount]['featureServers'][layerCount]['layers'].append(new)\n",
    "            \n",
    "            layerCount+=1\n",
    "\n",
    "    if \"folders\" in server['data']:\n",
    "        folderCount=0\n",
    "        folder2Count=0\n",
    "        fsCount=0 \n",
    "        msCount=0\n",
    "        for folder_name in server['data']['folders']:   # FOLDER LOOP\n",
    "            \n",
    "            folder_url=f\"{server['url']}/{folder_name}\"\n",
    "            folder_req=requests.get(f\"{folder_url}?f=pjson\")\n",
    "            folder_data=folder_req.json()           \n",
    "\n",
    "            if \"error\" in folder_data:\n",
    "                pass\n",
    "            else:\n",
    "                new={ \"url\": folder_url, \"name\": folder_name, \"services\": [ { \"featureServers\": [], \"mapServers\": [] } ] }\n",
    "                snapshot['servers'][serverCount]['folders'].append(new)\n",
    "                \n",
    "                fs=[]\n",
    "                ms=[]\n",
    "                errors=[]\n",
    "\n",
    "                for service in folder_data['services']: # GET F/S and M/S\n",
    "                    if service['type']=='FeatureServer':\n",
    "                        fs.append(f\"{service['name']}/{service['type']}\")\n",
    "                    elif service['type']=='MapServer':\n",
    "                        ms.append(f\"{service['name']}/{service['type']}\")\n",
    "                \n",
    "                fslCount=0\n",
    "                mslCount=0\n",
    "\n",
    "                for feature in fs:  # FEATURE SERVER LOOP\n",
    "                    url=f\"{server['url']}/{feature}\"\n",
    "                    feature_req=requests.get(f\"{url}/?f=pjson\")\n",
    "                    feature_data=(feature_req.json())\n",
    "                    \n",
    "                    if \"error\" in feature_data:\n",
    "                        new={ \"url\": url, \"name\": feature, \"layers\": \"Restricted\" }\n",
    "                        snapshot['servers'][serverCount]['folders'][folderCount]['services'][fsCount]['featureServers'].append(new)\n",
    "                    else:\n",
    "                        new={ \"url\": url, \"name\": feature, \"layers\": [] }\n",
    "                        snapshot['servers'][serverCount]['folders'][folderCount]['services'][fsCount]['featureServers'].append(new)\n",
    "                        for layer in feature_data['layers']:\n",
    "                            new={ \"url\": f\"{url}/{layer['id']}{query2}\", \"name\": layer['name'] }\n",
    "                            snapshot['servers'][serverCount]['folders'][folderCount]['services'][fsCount]['featureServers'][fslCount]['layers'].append(new)\n",
    "                        fslCount+=1\n",
    "                folderCount+=1\n",
    "\n",
    "                for feature in ms:  # MAP SERVER LOOP\n",
    "                    url=f\"{server['url']}/{feature}\"\n",
    "                    feature_req=requests.get(f\"{url}/?f=pjson\")\n",
    "                    feature_data=(feature_req.json())\n",
    "                    if \"error\" in feature_data:\n",
    "                        new={ \"url\": url, \"name\": feature, \"layers\": \"Restricted\" }\n",
    "                        snapshot['servers'][serverCount]['folders'][folder2Count]['services'][msCount]['mapServers'].append(new)\n",
    "                    else:\n",
    "                        new={ \"url\": url, \"name\": feature, \"layers\": [] }\n",
    "                        snapshot['servers'][serverCount]['folders'][folder2Count]['services'][msCount]['mapServers'].append(new)\n",
    "                        for layer in feature_data['layers']:\n",
    "                            new={ \"url\": f\"{url}/{layer['id']}{query2}\", \"name\": layer['name'] }\n",
    "                            snapshot['servers'][serverCount]['folders'][folder2Count]['services'][msCount]['mapServers'][mslCount]['layers'].append(new)\n",
    "                        mslCount+=1\n",
    "                folder2Count+=1\n",
    "    serverCount+=1    \n",
    "\n",
    "##############\n",
    "##############\n",
    "##          ##\n",
    "##   DONE   ##\n",
    "##          ##\n",
    "##############\n",
    "##############\n",
    "\n",
    "print(json.dumps(snapshot, indent=2))\n",
    "with open(f'../snapshots/snapshot-{date.today()}.json', 'w') as f:\n",
    "    json.dump(snapshot,f,indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
